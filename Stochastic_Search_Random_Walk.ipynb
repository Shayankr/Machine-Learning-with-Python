{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Stochastic Search Optimization Problem using Random Walk Concept with-in a Constrained Search Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic search algorithms are a family of optimization algorithms that use randomness as a key component in the search process. The basic idea is to use random sampling to generate candidate solutions, and then to use some criteria to determine which of these candidates should be chosen as the next point to be evaluated.\n",
    "\n",
    "There are several different types of stochastic search algorithms, including:\n",
    "\n",
    "* Monte Carlo optimization\n",
    "* Simulated Annealing\n",
    "* Genetic Algorithms\n",
    "* Particle Swarm Optimization\n",
    "\n",
    "Each of these algorithms has its own unique strengths and weaknesses, and the choice of which to use depends on the specific problem being solved and the desired trade-off between the speed of convergence and the quality of the solution. However, in general, stochastic search algorithms are useful for solving complex optimization problems where the search space is large and the optimal solution is not easily predictable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>What is Random Walk Stochastic Optimization problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Random walk stochastic optimization is a type of optimization problem where the objective function to be minimized is a random process. In other words, the value of the function is not deterministic, but instead depends on some underlying random variables. This type of optimization problem is often encountered in various fields such as finance, engineering, and physics.\n",
    "\n",
    "    In a random walk optimization problem, the optimization algorithm must be able to handle the randomness and uncertainty inherent in the problem, and it must be able to search for the optimal solution in the presence of this randomness. This can be a challenging task, as the traditional gradient-based optimization techniques are not well-suited for problems with randomness.\n",
    "\n",
    "    Stochastic search algorithms such as Monte Carlo optimization and Simulated Annealing are commonly used to solve random walk optimization problems. These algorithms work by using randomness in the search process to escape from local optima and to explore a wider range of the search space, making them well-suited for solving problems with complex, multi-modal objective functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a code to solve Random Walk optimization problem based on fitness score:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Here in the below code,</b>\n",
    "\n",
    "    the random_walk function takes in the objective function, the population size, the number of generations to run for, the step size for the random walk, and the fitness threshold for terminating the optimization. \n",
    "    \n",
    "    The function initializes a population of solutions and evaluates their fitness scores. \n",
    "    \n",
    "    Then, it repeatedly generates a new population by adding a random step to each solution and updates the best solution if a better one is found. \n",
    "    \n",
    "    The loop continues until the best fitness score is less than the fitness threshold or the maximum number of generations has been reached. \n",
    "    \n",
    "    The final best solution is returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement:\n",
    "#### The objective function has two variables \"x1\" and \"x2\" has y=-(5-(x1-2)**2-(x2-3)**2) then implement the Python code to find the optimized solution by using random-walk concept.\n",
    "\n",
    "#### if initial point is given as ((-2,2),(1,2),(0,0),(-1,-2),(3,1)).\n",
    "\n",
    "##### How can we put an extra constraint on the range of  x(x1,x2) input. Suppose my search space is rectangle space where X_min = (-3,-5) and X_max = (2,4). so my final solution solution should be inside this search space region , a rectangle formed by coordinate (-3,-5) and (2,4).  I have modified the code to meet this constraint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /config/.local/lib/python3.8/site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy in /config/.local/lib/python3.8/site-packages (1.24.2)\n",
      "Requirement already satisfied: matplotlib in /config/.local/lib/python3.8/site-packages (3.6.3)\n",
      "Requirement already satisfied: seaborn in /config/.local/lib/python3.8/site-packages (0.12.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /config/.local/lib/python3.8/site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /config/.local/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /config/.local/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /config/.local/lib/python3.8/site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /config/.local/lib/python3.8/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /config/.local/lib/python3.8/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /config/.local/lib/python3.8/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /config/.local/lib/python3.8/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /config/.local/lib/python3.8/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /config/.local/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas numpy matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we put an extra constraint on the range of  x(x1,x2) input. Suppose my search space is rectangle space where X_min = (-3,-5) and X_max = (2,4). so my final solution solution should be inside this search space region , a rectangle formed by coordinate (-3,-5) and (2,4).  I have modified the code to meet this constraint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution: (1, 2)\n",
      "The value of objective function at given initial popluation or solution sets are: [12, -3, 8, 29, 0]\n",
      "The value of the objective function ate best solution is: -3\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def objective_function(x):\n",
    "    x1, x2 = x\n",
    "    # Define your objective function here\n",
    "    return -(5-(x1-2)**2-(x2-3)**2)\n",
    "\n",
    "def random_walk(obj_func, population, number_of_generations, step_size, fitness_threshold, x_min, x_max):\n",
    "    best_fitness = float(\"inf\")\n",
    "    best_solution = None\n",
    "    \n",
    "    # Evaluate the fitness of the initial population\n",
    "    fitness_scores = [obj_func(x) for x in population]\n",
    "    \n",
    "    # Main loop\n",
    "    for i in range(number_of_generations):\n",
    "        # Update the best solution if a better one is found\n",
    "        best_index = np.argmin(fitness_scores)\n",
    "        if fitness_scores[best_index] < best_fitness:\n",
    "            best_fitness = fitness_scores[best_index]\n",
    "            best_solution = population[best_index]\n",
    "        \n",
    "        # Terminate the loop if the fitness threshold is reached\n",
    "        if best_fitness <= fitness_threshold:\n",
    "            break\n",
    "        \n",
    "        # Generate a new population by adding a random step to each solution\n",
    "        new_population = []\n",
    "        for x in population:\n",
    "            new_x1 = x[0] + random.uniform(-step_size, step_size)\n",
    "            new_x2 = x[1] + random.uniform(-step_size, step_size)\n",
    "            \n",
    "            # Ensure that the new solution is within the search space\n",
    "            new_x1 = max(x_min[0], min(x_max[0], new_x1))\n",
    "            new_x2 = max(x_min[1], min(x_max[1], new_x2))\n",
    "            \n",
    "            new_population.append((new_x1, new_x2))\n",
    "        population = new_population\n",
    "        \n",
    "        # Evaluate the fitness of the new population\n",
    "        fitness_scores = [obj_func(x) for x in population]\n",
    "    \n",
    "    return best_solution\n",
    "\n",
    "# Define the initial population\n",
    "initial_population = [(-2, 2), (1, 2), (0, 0), (-1, -2), (3, 1)]\n",
    "\n",
    "# Define the search space boundaries\n",
    "x_min = (-3, -5)\n",
    "x_max = (2, 4)\n",
    "\n",
    "result = random_walk(objective_function, initial_population, number_of_generations=1000, step_size=0.1, fitness_threshold=1e-6, x_min=x_min, x_max=x_max)\n",
    "print(\"Best solution:\", result)\n",
    "print(f\"The value of objective function at given initial popluation or solution sets are: {[objective_function(i) for i in initial_population]}\")\n",
    "print(f\"The value of the objective function ate best solution is: {objective_function(result)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this implementation, the population consists of tuples of x1 and x2 values, and the objective function takes in a tuple x and returns the value of y. The random_walk function initializing a population of solutions, updating the best solution if a better one is found, and generating new populations by adding random steps to each solution.\n",
    "\n",
    " The x_min and x_max are added as additional inputs to the random_walk function. In each iteration, before adding the random step to each solution, the new values of x1 and x2 are checked against the boundaries of the search space, and if they exceed the boundaries, they are truncated to the nearest boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Specified Initial Population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Now, If we donot initialize the population, then We can do slight modification in \"random_walk()\" function instead of \"population\" we can take \"population_size\" and we can randomly generate the initial population by using np.random() function.\n",
    "\n",
    "So, the code will be as shown below:\n",
    "[The below code is without Constraint we can also add constraint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution: (2.5385417916953728, 4.041080084907476)\n",
      "The value of the objective function ate best solution is: -3.6261249954065806\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def objective_function(x):\n",
    "    x1, x2 = x\n",
    "    # Define your objective function here\n",
    "    return -(5-(x1-2)**2-(x2-3)**2)\n",
    "\n",
    "def random_walk(obj_func, population_size, number_of_generations, step_size, fitness_threshold):\n",
    "    # Initialize the population\n",
    "    population = [(random.uniform(-10, 10), random.uniform(-10, 10)) for i in range(population_size)]\n",
    "    best_fitness = float(\"inf\")\n",
    "    best_solution = None\n",
    "    \n",
    "    # Evaluate the fitness of the initial population\n",
    "    fitness_scores = [obj_func(x) for x in population]\n",
    "    \n",
    "    # Main loop\n",
    "    for i in range(number_of_generations):\n",
    "        # Update the best solution if a better one is found\n",
    "        best_index = np.argmin(fitness_scores)\n",
    "        if fitness_scores[best_index] < best_fitness:\n",
    "            best_fitness = fitness_scores[best_index]\n",
    "            best_solution = population[best_index]\n",
    "        \n",
    "        # Terminate the loop if the fitness threshold is reached\n",
    "        if best_fitness <= fitness_threshold:\n",
    "            break\n",
    "        \n",
    "        # Generate a new population by adding a random step to each solution\n",
    "        new_population = [(x[0] + random.uniform(-step_size, step_size), x[1] + random.uniform(-step_size, step_size)) for x in population]\n",
    "        population = new_population\n",
    "        \n",
    "        # Evaluate the fitness of the new population\n",
    "        fitness_scores = [obj_func(x) for x in population]\n",
    "    \n",
    "    return best_solution\n",
    "\n",
    "result = random_walk(objective_function, population_size=100, number_of_generations=1000, step_size=0.1, fitness_threshold=1e-6)\n",
    "print(\"Best solution:\", result)\n",
    "\n",
    "print(f\"The value of the objective function ate best solution is: {objective_function(result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, Do not consider the Specific Initial population but put the constraint in search space as mentioned in above case:\n",
    "<b>Then the code will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution: (1.3477487610839733, 0.9512849253388506)\n",
      "The value of the objective function ate best solution is: -0.37733486418866935\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def objective_function(x):\n",
    "    x1, x2 = x\n",
    "    # Define your objective function here\n",
    "    return -(5-(x1-2)**2-(x2-3)**2)\n",
    "\n",
    "def random_walk(obj_func, number_of_generations, step_size, fitness_threshold, x_min, x_max):\n",
    "    best_fitness = float(\"inf\")\n",
    "    best_solution = None\n",
    "    \n",
    "    # Generate the initial solution\n",
    "    x1 = random.uniform(x_min[0], x_max[0])\n",
    "    x2 = random.uniform(x_min[1], x_max[1])\n",
    "    best_solution = (x1, x2)\n",
    "    best_fitness = obj_func(best_solution)\n",
    "    \n",
    "    # Main loop\n",
    "    for i in range(number_of_generations):\n",
    "        # Terminate the loop if the fitness threshold is reached\n",
    "        if best_fitness <= fitness_threshold:\n",
    "            break\n",
    "        \n",
    "        # Generate a new solution by adding a random step to the best solution\n",
    "        new_x1 = best_solution[0] + random.uniform(-step_size, step_size)\n",
    "        new_x2 = best_solution[1] + random.uniform(-step_size, step_size)\n",
    "        \n",
    "        # Ensure that the new solution is within the search space\n",
    "        new_x1 = max(x_min[0], min(x_max[0], new_x1))\n",
    "        new_x2 = max(x_min[1], min(x_max[1], new_x2))\n",
    "        \n",
    "        new_solution = (new_x1, new_x2)\n",
    "        new_fitness = obj_func(new_solution)\n",
    "        \n",
    "        # Update the best solution if a better one is found\n",
    "        if new_fitness < best_fitness:\n",
    "            best_fitness = new_fitness\n",
    "            best_solution = new_solution\n",
    "    \n",
    "    return best_solution\n",
    "\n",
    "# Define the search space boundaries\n",
    "x_min = (-3, -5)\n",
    "x_max = (2, 4)\n",
    "\n",
    "result = random_walk(objective_function, number_of_generations=1000, step_size=0.1, fitness_threshold=1e-6, x_min=x_min, x_max=x_max)\n",
    "print(\"Best solution:\", result)\n",
    "\n",
    "print(f\"The value of the objective function ate best solution is: {objective_function(result)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>From this last code and above constrained optimized code, We can see the variation in results in \"Stochastic Optimization Approach\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
